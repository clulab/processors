CluProcessor {
  internStrings = false

  mtl-ner = "org/clulab/processors/clu/crf-avg-e5e4e15"
  mtl-pos-chunk-srlp = "org/clulab/processors/clu/mtl-en-pos-chunk-srlp-avg-e6e1e11e5e7"
  mtl-srla = "org/clulab/processors/clu/mtl-en-srla-avg-e3e5e2e6e4"

  // trained on the original UD En corpus; this has strange annotations; better not use
  //mtl-depsh = "org/clulab/processors/clu/mtl-en-depsh-avg-e4e6e7e8e3"
  //mtl-depsl = "org/clulab/processors/clu/mtl-en-depsl-avg-e4e5e3e1e6"

  // trained on WSJ + Genia
  //mtl-depsh = "org/clulab/processors/clu/mtl-en-wsjgeniadepsh-avg-e9e4e10e11e6"
  //mtl-depsl = "org/clulab/processors/clu/mtl-en-wsjgeniadepsl-avg-e9e4e6e8e7"

  // trained on WSJ + Genia using MTL (both depsh and depsl)
  //mtl-deps = "org/clulab/processors/clu/mtl-en-wsjgeniadeps-avg-e1e6e10e11e7"

  // separate models, each trained on WSJ + Genia. Slimmer, but perform well
  mtl-depsh = "org/clulab/processors/clu/mtl-en-depsh-h128-e9e12e13e4e10"
  mtl-depsl = "org/clulab/processors/clu/mtl-en-depsl-h128l1d64neg4-e9e4e12e10e13"

  // case restoration models
  mtl-case = "org/clulab/processors/clu/mtl-en-case-e1e2e3"
}