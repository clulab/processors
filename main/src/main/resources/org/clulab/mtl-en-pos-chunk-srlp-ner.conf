mtl {
	shardsPerEpoch = 10
	maxEpochs = 50
	epochPatience = 5
	numberOfTasks = 4

	layers {
		initial {
			learnedWordEmbeddingSize = 128
			charEmbeddingSize = 32
			charRnnStateSize = 16
			c2i = "org/clulab/c2i-en.txt"
		}

		intermediate1 {
			rnnStateSize = 128
			useHighwayConnections = false
			numLayers = 1
		}
	}

	task1 {
		name = "En POS tagging"
		train = "/data/nlp/corpora/processors-dynet/en/pos/train.txt"
		dev = "/data/nlp/corpora/processors-dynet/en/pos/dev.txt"
		test = "/data/nlp/corpora/processors-dynet/en/pos/test.txt"

		layers {
			final {
				inference = "greedy"
			}
		}
	}

	task2 {
		name = "En chunking"
		train = "/data/nlp/corpora/processors-dynet/en/chunking/train.txt"
		dev = "/data/nlp/corpora/processors-dynet/en/chunking/test.txt"
		test = "/data/nlp/corpora/processors-dynet/en/chunking/test.txt"

		layers {
			final {
				inference = "viterbi"
			}
		}
	}

	task3 {
		name = "En SRL predicates"
		train = "/data/nlp/corpora/processors-dynet/en/srl/train.preds"
		dev = "/data/nlp/corpora/processors-dynet/en/srl/dev.preds"
		test = "/data/nlp/corpora/processors-dynet/en/srl/test-wsj.preds"

		layers {
			final {
				inference = "greedy"
			}
		}
	}

	task4 {
		name = "En NER"
		train = "/data/nlp/corpora/processors-dynet/en/ner/train.txt"
		dev = "/data/nlp/corpora/processors-dynet/en/ner/dev.txt"
		test = "/data/nlp/corpora/processors-dynet/en/ner/test.txt"

		layers {
		final {
			inference = "viterbi"
		}
		}
  	}
}